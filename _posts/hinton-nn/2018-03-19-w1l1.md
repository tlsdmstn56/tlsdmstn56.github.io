---
layout: single
title: "[Hinton NN] Lecture 1 - Introduction to the course - machine learning and neural nets"
tags: ["Deep Learning","Coursera"]
date: 2018-03-19 01:00:00
categories:
  - "딥러닝 강의 - 제프리 힌튼"
---
## 왜 머신러닝이 필요한가

### 머신러닝이란
* 완전히 새로운 시점에서 3차원 물체를 인식하는 프로그램을 짜는 것은 매우 어렵다. 
  * 우리는 어떤 프로그램을 짜야하는 지 모른다.
  * 우리가 어떤 프로그램을 짜야하는 지 좋은 아이디어가 있더라도 매우 복잡하다.
* 신용카드 거래가 사기일 확률을 계산하는 프로그램을 짜는 것은 매우 어렵다.
  * 간단하면서도 신뢰성 있는 규칙이 없을 수 있기 때문이다.
  * 사기의 형태는 계속 변화하므로 프로그램도 같이 변화해야 한다.

### 머신러닝의 접근 방식
* 모든 케이스를 따져가며 프로그램을 짜기 보다는 주어진 입력 값에 대한 올바른 출력값을 가지는 많은 예시 (또는 자료)들을 수집한다.
* 머신러닝은 이러한 자료들을 받아 그런 작업들을 할 수 있는 프로그램들을 만들어낸다.
  * 학습 알고리즘에 의해 만들어진 프로그램은 hand-written 프로그램과는 다르다. 
  * 만약 제대로만 했다면 그 프로그램은 새로운 경우에 대해서도 잘 작동한다.
  * 새로운 데이터를 학습함으로써 프로그램도 변화할 수 있다.

### 학습에 의해 해결될 수 있는 문제들
* 패턴 인식
* Anomalies 인식
* 예측

## 신경망(NN: Neural Net)이란 무엇인가

### Neural Computation을 배우는 이유
* 뇌가 실제로 어떻게 작동하는지 이해하기 위해
* Neuron과 Adaptive Connection에 의해 발생하는 parallel computation의 스타일을 이해하기 위해

## Neuron의 간단한 모델들

### 이상화된 Neuron
 * 이해하기 쉽게 해준다.

### Linear Neurons
$$ y=b+\sum_{i}x_i w_i $$
* 간단하지만 계산상의 한계점이 있다.
* $$y$$: output
* $$b$$: bias
* $$x_i$$: i-th input
* $$w_i$$: weight on i-th input

![linear neuron]({{ site.url }}/assets/hinton_nn/nn_w1l1_linear_neurons.png)

### Binary threshold neurons
![binary threshold neurons]({{ site.url }}/assets/hinton_nn/nn_w1l1_binary_threshold_neurons.png)

아래 두 식은 동일하다.

$$ z = \sum_i x_i w_i $$ 

$$ y = \begin{cases}
    1 & \text{if $ z \geq \theta $}.\\
    0 & \text{otherwise}.
  \end{cases} $$

$$ z = b+\sum_i x_i w_i $$ 

$$ y = \begin{cases}
    1 & \text{if $ z \geq 0 $}.\\
    0 & \text{otherwise}.
  \end{cases} $$

### Rectified Linear Neurons
Linear Threshold Neurons으로 불리기도 한다.
* Input: **linear** weighted sum
* Output: **non-linear** function of totla input

![rectified linear neurons]({{ site.url }}/assets/hinton_nn/nn_w1l1_rectified_linear_neurons.png)

$$ z = b + \sum_i x_i w_i $$

$$ y = \begin{cases}
    z & \text{if $ z \geq 0 $}.\\
    0 & \text{otherwise}.
  \end{cases} $$

### Sigmoid Neurons
* These give a real-valuedoutput that is a smooth and bounded function of their total input.
* 학습을 쉽게 해주는 좋은 미분 형태를 가진다.

![sigmomid neurons]({{ site.url }}/assets/hinton_nn/nn_w1l1_sigmoid_neurons.png)

$$ z=b+\sum_i x_i w_i $$

$$ y = \frac{1}{1+e^{-z}} $$

### Stochastic binary neurons
* logistic units과 같은 방정식을 사용한다.
  * 로지스틱 함수의 output을 spike가 발생할 확률로 취급한다.
* rectified linear unit과 비슷한 트릭을 사용할 수 있다.
  * output은 포아송 rate로 볼 수 있다.

![stochastic binary neurons]({{ site.url }}/assets/hinton_nn/nn_w1l1_stochastic_binary_neurons.png)

$$ z=b+\sum_i x_i w_i $$

$$ p(s=1) = \frac{1}{1+e^{-z}} $$

## 학습의 간단한 예시
생략

## 학습의 세 가지 종류
### 학습의 종류
* Supervised learning - Learn to predict an output when given an input vector.
* Reinforcement learning -Learn to select an action to maximize payoff.
* Unsupervised learning - Discover a good internal representation of the input.

### Supervised Learning의 종류
각 training case는 target output을 가지고 있음
* Regression
* Classification

### Supervised learning의 작동 원리
* **model-class**를 설정한다: $$y=f(\mathbf{x},\mathbf{W})$$
  * A model-class $$f$$는 numerical한 파라미터인 $$\mathbf{W}$$를 가지고 각 input 벡터 $$\mathbf{x}$$ 를 predicted output인 $$y$$로 맵핑한다.
* 타겟 output과 실제 output과의 차이를 줄이도록 파라미터를 조정하는 식으로 학습한다.
  * regression에서는 $$\frac{1}{2} (y-t)^2 $$를 사용
  * classification에서는 다른 방법을 사용

### Reinforcement Learning

### Unsupervised Learning